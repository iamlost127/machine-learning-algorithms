{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Logistic Regression\n",
    "\n",
    "*Logistic Regression using negative log likelihood loss with $L_2$ regularization penalty*\n",
    "\n",
    "---\n",
    "* [Theory and Derivation](../theory/logistic_regression.ipynb)\n",
    "* [Implementation in Python](../pymlalgo/regression/regularised_logistic_regression.py)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "**Using the [digits dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) with two classes to demo the implementation of Logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "digits = load_digits(n_class = 2)\n",
    "predictors = digits.data\n",
    "response = digits.target\n",
    "x = np.asarray(predictors)\n",
    "y = np.asarray(response).reshape(-1, 1)\n",
    "y = np.where(y==0,-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "**Train, test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((294, 64), (72, 64), (294, 1), (72, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymlalgo.util.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "**Normalizing the Data as** $\\frac{x-\\mu}{\\sigma}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from pymlalgo.util.standardization import Standardizer\n",
    "x_standardizer = Standardizer(x_train)\n",
    "x_train = x_standardizer.standardize(x_train)\n",
    "x_test = x_standardizer.standardize(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "**Training the model using `LogisticRegression`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from pymlalgo.regression.regularised_logistic_regression import LogisticRegression\n",
    "lamb = 1\n",
    "logistic_model = LogisticRegression(x_train, y_train, lamd=lamb, eps=1e-4, max_iterations=1000)\n",
    "logistic_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "**Cost history vs number of iterations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(logistic_model.cost_history_fastgrad[1:])\n",
    "plt.xlabel('Iteration Count')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Cost History vs Iteration');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "**Misclassification error reported on train and test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996599</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_score  test_score\n",
       "0     0.996599         1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'train_score' : [logistic_model.score(x_train, y_train)], \n",
    "              'test_score': [logistic_model.score(x_test, y_test)]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "**Comparison with `sklearn`**  \n",
    "\n",
    "The cost function in `sklearn` is $$ F(\\beta) = \\frac{||Y - X^T\\beta||_2^2 + C ||\\beta||_2^2}{2m}$$\n",
    "To make it equivalent to the cost function in current implementation, $$\\lambda = \\frac{1}{2*m*C}$$, where m is number of training samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0017006802721088435, class_weight=None, dual=False,\n",
       "          fit_intercept=False, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=42,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>sk_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000641</td>\n",
       "      <td>-0.000638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.015974</td>\n",
       "      <td>-0.015961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.044998</td>\n",
       "      <td>-0.044999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.015942</td>\n",
       "      <td>-0.015941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.042122</td>\n",
       "      <td>0.042134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.039379</td>\n",
       "      <td>0.039389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.025778</td>\n",
       "      <td>-0.025774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.064373</td>\n",
       "      <td>-0.064364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.012909</td>\n",
       "      <td>-0.012910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.025129</td>\n",
       "      <td>0.025139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.020036</td>\n",
       "      <td>-0.020033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.013940</td>\n",
       "      <td>0.013943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.010086</td>\n",
       "      <td>0.010088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.032959</td>\n",
       "      <td>-0.032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.055917</td>\n",
       "      <td>-0.055911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.078315</td>\n",
       "      <td>0.078323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.090925</td>\n",
       "      <td>0.090943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.039517</td>\n",
       "      <td>-0.039517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.044754</td>\n",
       "      <td>-0.044754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.010078</td>\n",
       "      <td>0.010079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.044012</td>\n",
       "      <td>-0.044008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.034343</td>\n",
       "      <td>-0.034340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.083986</td>\n",
       "      <td>0.083993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.095191</td>\n",
       "      <td>0.095205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.024126</td>\n",
       "      <td>-0.024129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.045113</td>\n",
       "      <td>-0.045112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.076338</td>\n",
       "      <td>0.076347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.095276</td>\n",
       "      <td>0.095287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-0.028009</td>\n",
       "      <td>-0.028017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.081301</td>\n",
       "      <td>-0.081302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.057066</td>\n",
       "      <td>-0.057057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.068958</td>\n",
       "      <td>-0.068957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.061609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.086686</td>\n",
       "      <td>0.086690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.047573</td>\n",
       "      <td>-0.047586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.066793</td>\n",
       "      <td>-0.066791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.025808</td>\n",
       "      <td>-0.025797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-0.069736</td>\n",
       "      <td>-0.069732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-0.002407</td>\n",
       "      <td>-0.002410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.031240</td>\n",
       "      <td>0.031233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-0.042561</td>\n",
       "      <td>-0.042565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>-0.000718</td>\n",
       "      <td>-0.000714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.020418</td>\n",
       "      <td>0.020416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.001913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-0.021058</td>\n",
       "      <td>-0.021045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-0.049565</td>\n",
       "      <td>-0.049569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-0.008111</td>\n",
       "      <td>-0.008113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.038481</td>\n",
       "      <td>0.038489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.036878</td>\n",
       "      <td>0.036879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.025064</td>\n",
       "      <td>0.025061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        coef   sk_coef\n",
       "0   0.000000  0.000000\n",
       "1  -0.000641 -0.000638\n",
       "2  -0.015974 -0.015961\n",
       "3  -0.044998 -0.044999\n",
       "4  -0.015942 -0.015941\n",
       "5   0.042122  0.042134\n",
       "6   0.039379  0.039389\n",
       "7   0.000000  0.000000\n",
       "8   0.000000  0.000000\n",
       "9  -0.025778 -0.025774\n",
       "10 -0.064373 -0.064364\n",
       "11 -0.012909 -0.012910\n",
       "12  0.025129  0.025139\n",
       "13 -0.020036 -0.020033\n",
       "14  0.013940  0.013943\n",
       "15  0.000000  0.000000\n",
       "16  0.010086  0.010088\n",
       "17 -0.032959 -0.032949\n",
       "18 -0.055917 -0.055911\n",
       "19  0.078315  0.078323\n",
       "20  0.090925  0.090943\n",
       "21 -0.039517 -0.039517\n",
       "22 -0.044754 -0.044754\n",
       "23  0.000000  0.000000\n",
       "24  0.010078  0.010079\n",
       "25 -0.044012 -0.044008\n",
       "26 -0.034343 -0.034340\n",
       "27  0.083986  0.083993\n",
       "28  0.095191  0.095205\n",
       "29 -0.024126 -0.024129\n",
       "..       ...       ...\n",
       "34 -0.045113 -0.045112\n",
       "35  0.076338  0.076347\n",
       "36  0.095276  0.095287\n",
       "37 -0.028009 -0.028017\n",
       "38 -0.081301 -0.081302\n",
       "39  0.000000  0.000000\n",
       "40  0.000000  0.000000\n",
       "41 -0.057066 -0.057057\n",
       "42 -0.068958 -0.068957\n",
       "43  0.061600  0.061609\n",
       "44  0.086686  0.086690\n",
       "45 -0.047573 -0.047586\n",
       "46 -0.066793 -0.066791\n",
       "47  0.000000  0.000000\n",
       "48  0.000000  0.000000\n",
       "49 -0.025808 -0.025797\n",
       "50 -0.069736 -0.069732\n",
       "51 -0.002407 -0.002410\n",
       "52  0.031240  0.031233\n",
       "53 -0.042561 -0.042565\n",
       "54 -0.000718 -0.000714\n",
       "55  0.020418  0.020416\n",
       "56  0.000000  0.000000\n",
       "57  0.001913  0.001913\n",
       "58 -0.021058 -0.021045\n",
       "59 -0.049565 -0.049569\n",
       "60 -0.008111 -0.008113\n",
       "61  0.038481  0.038489\n",
       "62  0.036878  0.036879\n",
       "63  0.025064  0.025061\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "alpha = 1/(2*len(x_train)*lamb)\n",
    "logistic_sk = LogisticRegression(C = alpha, random_state = 42,fit_intercept=False, solver = 'lbfgs')\n",
    "logistic_sk.fit(x_train, y_train.ravel())\n",
    "\n",
    "pd.DataFrame({'coef': logistic_model.beta.flatten(), 'sk_coef' : logistic_sk.coef_.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>train_score_sk</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_score_sk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996599</td>\n",
       "      <td>0.996599</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_score  train_score_sk  test_score  test_score_sk\n",
       "0     0.996599        0.996599         1.0            1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'train_score' : [logistic_model.score(x_train, y_train)], \n",
    "              'train_score_sk' : [logistic_sk.score(x_train, y_train)],\n",
    "              'test_score': [logistic_model.score(x_test, y_test)],\n",
    "              'test_score_sk' : [logistic_sk.score(x_test, y_test)]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
